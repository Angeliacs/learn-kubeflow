{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief Introduction of [Kubeflow Pipeline](https://www.kubeflow.org/docs/pipelines/pipelines-overview/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is Kubeflow pipeline?\n",
    "* It is just like AML Studio experiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What is Kubeflow [component](https://www.kubeflow.org/docs/pipelines/concepts/component/)?\n",
    "* A pipeline has many components, and a component is just like a step in AML Studio experiment.\n",
    "\n",
    "* A component has a **Docker image** (source codes) and an **interface**, which specifies the input/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. How to write pipeline and component?\n",
    "* Use [Kubeflow Pipelines SDK](https://www.kubeflow.org/docs/pipelines/sdk/), and follow the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Put source code into a Docker image. To do that, first [install docker](https://docs.docker.com/docker-for-windows/install/). Then write a [Dockerfile](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/). Build the docker image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2**: Register Docker image to [Dockerhub](https://cloud.docker.com/u/guobowen1990/repository/docker/guobowen1990/cnn-demo) or [GCR (Google Container Registry)](https://console.cloud.google.com/gcr/images/kubeflow-trial-241202?project=kubeflow-trial-241202&folder&organizationId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeate Steps 1 and 2 for every component of pipeline, since every component needs a Docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3**: Now component part is almost done (not done yet).Then we need to write a **yaml file** as an **intermediate representation** of the pipeline.\n",
    "\n",
    "* The yaml file is generated by Kubeflow Pipeline SDK, to be more specific, the [**kfp.dsl**](https://www.kubeflow.org/docs/pipelines/sdk/dsl-overview/) package. BTW, DSL stands for domain-specific language.\n",
    "   \n",
    "* Below is a small python program to demonstrate how to use SDK to generate yaml file. Basically this program does two things: 1. Define a component interface and 2. define a pipeline by connecting all the components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ```python\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "\n",
    "\n",
    "def gcs_download_op(url):\n",
    "    \"\"\"\n",
    "     Define component 1\n",
    "    \"\"\"\n",
    "    return dsl.ContainerOp(\n",
    "        name='GCS - Download',\n",
    "        image='google/cloud-sdk:216.0.0',\n",
    "        command=['sh', '-c'],\n",
    "        arguments=['gsutil cat $0 | tee $1', url, '/tmp/results.txt'],\n",
    "        file_outputs={\n",
    "            'data': '/tmp/results.txt',\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def echo_op(text):\n",
    "    \"\"\"\n",
    "     Define component 2\n",
    "    \"\"\"\n",
    "    return dsl.ContainerOp(\n",
    "        name='echo',\n",
    "        image='library/bash:4.4.23',\n",
    "        command=['sh', '-c'],\n",
    "        arguments=['echo \"$0\"', text]\n",
    "    )\n",
    "    \n",
    "@dsl.pipeline(\n",
    "    name='Sequential pipeline',\n",
    "    description='A pipeline with two sequential steps.'\n",
    ")\n",
    "def sequential_pipeline(url='gs://ml-pipeline-playground/shakespeare1.txt'):\n",
    "    \"\"\"A pipeline with two sequential steps.\"\"\"\n",
    "\n",
    "    download_task = gcs_download_op(url)\n",
    "    echo_task = echo_op(download_task.output)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kfp.compiler.Compiler().compile(sequential_pipeline, __file__ + '.zip')\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When use the following command to generate the yaml file: demo.yaml\n",
    "\n",
    "dsl-compile --py [path/to/python/file] --output demo.yaml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4**: Now it is time to deploy the pipeline! To do that, simply upload the yaml file to Kubeflow UI, then you "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PowerShell",
   "language": "powershell",
   "name": "powershell"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".ps1",
   "mimetype": "text/x-sh",
   "name": "powershell"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
